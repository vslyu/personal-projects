
### 机器学习编程框架

ELF：map-reduce框架。对用户提供的主要抽象就是分布式数据流。用户同对一个数据源对象进行一些变换后得到一些新的数据流。最后通过用户将数据流的尾端点加入执行计划。并最终执行来得到结果。

提供了分布式kv存取的操作，但是不是像pull／push这种灵活操作，只能在数据流上做lookup和aggregate，像是加强版的reduce。

Hippo：容错、动态扩缩容。提供了通用的参数服务器。有调度模块、worker模块、ps模块。它的目标是更快（数据按需分配），更省（动态扩缩容），更稳定（容错）。
 - 容错，某一节点出错。其他节点可以继续训练。虽然某些数据可能会重复训练，但实测影响极小。
 - 节点数可以动态变化，比如当执行最后一轮，先跑完的节点先释放掉，ps和worker资源的配置可以不同。当部分worker起来了，作业就可以跑起来了，然后随着新的资源被满足，不断有worker加进来。
 - 每个节点分到一批数据，消费完了再申请。这样的话，对于很慢的节点，它消费的很慢，其他快的节点申请的比它多，一定程度上缓解了慢节点的问题。
 - 当发现有慢节点，把它释放掉，加入黑名单，重新申请新节点。


### 学习率与batch size

[https://www.cnblogs.com/yumoye/p/11055813.html](https://www.cnblogs.com/yumoye/p/11055813.html)
